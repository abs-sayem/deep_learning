{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summarization: An Unsupervised Extractive Way**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **There are two types of approach for text summarization: 1) Supervised and 2) Unsupervised. And in terms of summaries, there are two types of summaries: 1) Extractive and 2) Abstractive.<br>Here, we will use a Unsupervised extractive method.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Steps**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. Generate Embedding Model**\n",
    "###### **Embedding selects sentences that contain words with the same meaning as the most relevant words — even if the words are different. So, before even preprocessing the text, the program must define the embedding model. To obtain the word embedding, I split the text into words and passed it to Word2vec.** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2. Preprocessing**\n",
    "###### **Preprocessing includes splitting the text into sentences, lowering the case of all words, removing stopwords (is, an, the, etc.) and punctuation and other tasks. Especifically to identifying and splitting the text into sentences, the algorithm will score and select them to be part of the summary.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3. Find Most Relevant Words Embedding Representation**\n",
    "###### **The algorithm uses TF-IDF to find the most relevant words of the text. These words are the centroid of the text. After finding the words centroid, the program sums up the vectors of the words that are part of the centroid, and that sum is the embedding representation of the centroid.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4. Score Sentences**\n",
    "###### **The sentences are scored based on how similar they are to the centroid embedding. In order to compare to the centroid embedding, the algorithm calculates the embedding representation of each sentence.**\n",
    "###### ***`Sentence embedding = sum of words vectors that are part of the sentence.`***\n",
    "###### **Lastly, after the sentence embedding is defined, the algorithm uses cosine similarity to calculate the similarity between the centroid and the sentence embedding. Each sentence gets a score based on how similar they are to the centroid.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5. Select Sentences and Resolve Redundancy**\n",
    "###### **The sentences are selected based on their score. The number of sentences selected is limited by how many words the summary should contain (50 words, 100 words, or?). A common problem when dealing with automatic summarization is handling redundancy — too similar sentences being part of the summary. To overcome that, when selecting the sentences, you compare them with the sentences already in summary. If a chosen sentence is too similar to one in summary, you don’t add it to the final text. The algorithm uses cosine similarity with some predefined threshold when making the comparison.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lets Get Started**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize as nlkt_sent_tokenize\n",
    "from nltk.tokenize import word_tokenize as nlkt_word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates cosine similarity\n",
    "def similarity(v1, v2):\n",
    "    score = 0.0\n",
    "    if np.count_nonzero(v1) != 0 and np.count_nonzero(v2) != 0:\n",
    "        score = ((1 - cosine(v1, v2)) + 1) / 2\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer\n",
    "def sent_tokenize(text):\n",
    "    sents = nlkt_sent_tokenize(text)\n",
    "    sents_filtered = []\n",
    "    for s in sents:\n",
    "        sents_filtered.append(s)\n",
    "    return sents_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessor\n",
    "def cleanup_sentences(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentences_cleaned = []\n",
    "    for sent in sentences:\n",
    "        words = nlkt_word_tokenize(sent)\n",
    "        words = [w for w in words if w not in string.punctuation]\n",
    "        words = [w for w in words if not w.lower() in stop_words]\n",
    "        words = [w.lower() for w in words]\n",
    "        sentences_cleaned.append(\" \".join(words))\n",
    "    return sentences_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Word-Embedding module\n",
    "def get_tf_idf(sentences):\n",
    "    vectorizer = CountVectorizer()\n",
    "    sent_word_matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    transformer = TfidfTransformer(norm=None, sublinear_tf=False, smooth_idf=False)\n",
    "    tfidf = transformer.fit_transform(sent_word_matrix)\n",
    "    tfidf = tfidf.toarray()\n",
    "\n",
    "    centroid_vector = tfidf.sum(0)\n",
    "    centroid_vector = np.divide(centroid_vector, centroid_vector.max())\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    relevant_vector_indices = np.where(centroid_vector > 0.3)[0]\n",
    "\n",
    "    word_list = list(np.array(feature_names)[relevant_vector_indices])\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word-Embedding Cache\n",
    "# Populate word vector with all embeddings.\n",
    "# This word vector is a look up table that is used for getting the centroid and sentences embedding representation.\n",
    "def word_vectors_cache(sentences, embedding_model):\n",
    "    word_vectors = dict()\n",
    "    for sent in sentences:\n",
    "        words = nlkt_word_tokenize(sent)\n",
    "        for w in words:\n",
    "            word_vectors.update({w: embedding_model.wv[w]})\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence embedding\n",
    "# Sentence embedding representation with sum of word vectors\n",
    "def build_embedding_representation(words, word_vectors, embedding_model):\n",
    "    embedding_representation = np.zeros(embedding_model.vector_size, dtype=\"float32\")\n",
    "    word_vectors_keys = set(word_vectors.keys())\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in word_vectors_keys:\n",
    "            embedding_representation = embedding_representation + word_vectors[w]\n",
    "            count += 1\n",
    "    if count != 0:\n",
    "       embedding_representation = np.divide(embedding_representation, count)\n",
    "    return embedding_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizer\n",
    "def summarize(text, emdedding_model):\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    clean_sentences = cleanup_sentences(text)\n",
    "    for i, s in enumerate(raw_sentences):\n",
    "        print(i, s)\n",
    "    for i, s in enumerate(clean_sentences):\n",
    "        print(i, s)\n",
    "    centroid_words = get_tf_idf(clean_sentences)\n",
    "    print(len(centroid_words), centroid_words)\n",
    "    word_vectors = word_vectors_cache(clean_sentences, emdedding_model)\n",
    "    #Centroid embedding representation\n",
    "    centroid_vector = build_embedding_representation(centroid_words, word_vectors, emdedding_model)\n",
    "    sentences_scores = []\n",
    "    for i in range(len(clean_sentences)):\n",
    "        scores = []\n",
    "        words = clean_sentences[i].split()\n",
    "\n",
    "        #Sentence embedding representation\n",
    "        sentence_vector = build_embedding_representation(words, word_vectors, emdedding_model)\n",
    "\n",
    "        #Cosine similarity between sentence embedding and centroid embedding\n",
    "        score = similarity(sentence_vector, centroid_vector)\n",
    "        sentences_scores.append((i, raw_sentences[i], score, sentence_vector))\n",
    "    sentence_scores_sort = sorted(sentences_scores, key=lambda el: el[2], reverse=True)\n",
    "    for s in sentence_scores_sort:\n",
    "        print(s[0], s[1], s[2])\n",
    "    count = 0\n",
    "    sentences_summary = []\n",
    "    #Handle redundancy\n",
    "    for s in sentence_scores_sort:\n",
    "        if count > 100:\n",
    "            break\n",
    "        include_flag = True\n",
    "        for ps in sentences_summary:\n",
    "            sim = similarity(s[3], ps[3])\n",
    "            if sim > 0.95:\n",
    "                include_flag = False\n",
    "        if include_flag:\n",
    "            sentences_summary.append(s)\n",
    "            count += len(s[1].split())\n",
    "\n",
    "        sentences_summary = sorted(sentences_summary, key=lambda el: el[0], reverse=False)\n",
    "\n",
    "    summary = \"\\n\".join([s[1] for s in sentences_summary])\n",
    "    print(summary)\n",
    "    #return summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Summarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills. Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services. As part of the program, the Redmond giant which wants to expand its reach and is planning to build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT Hub for the selected campuses. The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning. According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset. This will require more collaborations and training and working with AI. That’s why it has become more critical than ever for educational institutions to integrate new cloud and AI technologies. The program is an attempt to ramp up the institutional set-up and build capabilities among the educators to educate the workforce of tomorrow.\"The program aims to build up the cognitive skills and in-depth understanding of developing intelligent cloud connected solutions for applications across industry. Earlier in April this year, the company announced Microsoft Professional Program In AI as a learning track open to the public. The program was developed to provide job ready skills to programmers who wanted to hone their skills in AI and data science with a series of online courses which featured hands-on labs and expert instructors as well. This program also included developer-focused AI school that provided a bunch of assets to help build AI skills.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills.\n",
      "1 Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services.\n",
      "2 As part of the program, the Redmond giant which wants to expand its reach and is planning to build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT Hub for the selected campuses.\n",
      "3 The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning.\n",
      "4 According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset.\n",
      "5 This will require more collaborations and training and working with AI.\n",
      "6 That’s why it has become more critical than ever for educational institutions to integrate new cloud and AI technologies.\n",
      "7 The program is an attempt to ramp up the institutional set-up and build capabilities among the educators to educate the workforce of tomorrow.\n",
      "8 \"The program aims to build up the cognitive skills and in-depth understanding of developing intelligent cloud connected solutions for applications across industry.\n",
      "9 Earlier in April this year, the company announced Microsoft Professional Program In AI as a learning track open to the public.\n",
      "10 The program was developed to provide job ready skills to programmers who wanted to hone their skills in AI and data science with a series of online courses which featured hands-on labs and expert instructors as well.\n",
      "11 This program also included developer-focused AI school that provided a bunch of assets to help build AI skills.\n",
      "0 attempt build ai-ready workforce microsoft announced intelligent cloud hub launched empower next generation students ai-ready skills\n",
      "1 envisioned three-year collaborative program intelligent cloud hub support around 100 institutions ai infrastructure course content curriculum developer support development tools give students access cloud ai services\n",
      "2 part program redmond giant wants expand reach planning build strong developer ecosystem india program set core ai infrastructure iot hub selected campuses\n",
      "3 company provide ai development tools azure ai services microsoft cognitive services bot services azure machine learning\n",
      "4 according manish prakash country general manager-ps health education microsoft india said `` ai defining technology time transforming lives industry jobs tomorrow require different skillset\n",
      "5 require collaborations training working ai\n",
      "6 ’ become critical ever educational institutions integrate new cloud ai technologies\n",
      "7 program attempt ramp institutional set-up build capabilities among educators educate workforce tomorrow\n",
      "8 `` program aims build cognitive skills in-depth understanding developing intelligent cloud connected solutions applications across industry\n",
      "9 earlier april year company announced microsoft professional program ai learning track open public\n",
      "10 program developed provide job ready skills programmers wanted hone skills ai data science series online courses featured hands-on labs expert instructors well\n",
      "11 program also included developer-focused ai school provided bunch assets help build ai skills\n",
      "31 ['ai', 'announced', 'attempt', 'azure', 'build', 'cloud', 'cognitive', 'company', 'developer', 'development', 'hub', 'india', 'industry', 'infrastructure', 'institutions', 'intelligent', 'learning', 'microsoft', 'program', 'provide', 'ready', 'require', 'services', 'set', 'skills', 'students', 'support', 'tomorrow', 'tools', 'workforce', 'year']\n",
      "1 Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services. 0.832622230052948\n",
      "3 The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning. 0.7902283072471619\n",
      "0 In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills. 0.7395225018262863\n",
      "9 Earlier in April this year, the company announced Microsoft Professional Program In AI as a learning track open to the public. 0.7172102779150009\n",
      "2 As part of the program, the Redmond giant which wants to expand its reach and is planning to build a strong developer ecosystem in India with the program will set up the core AI infrastructure and IoT Hub for the selected campuses. 0.7136569768190384\n",
      "11 This program also included developer-focused AI school that provided a bunch of assets to help build AI skills. 0.7010509222745895\n",
      "8 \"The program aims to build up the cognitive skills and in-depth understanding of developing intelligent cloud connected solutions for applications across industry. 0.6959008574485779\n",
      "10 The program was developed to provide job ready skills to programmers who wanted to hone their skills in AI and data science with a series of online courses which featured hands-on labs and expert instructors as well. 0.6866663098335266\n",
      "4 According to Manish Prakash, Country General Manager-PS, Health and Education, Microsoft India, said, \"With AI being the defining technology of our time, it is transforming lives and industry and the jobs of tomorrow will require a different skillset. 0.6724038869142532\n",
      "6 That’s why it has become more critical than ever for educational institutions to integrate new cloud and AI technologies. 0.6223014369606972\n",
      "5 This will require more collaborations and training and working with AI. 0.6070081144571304\n",
      "7 The program is an attempt to ramp up the institutional set-up and build capabilities among the educators to educate the workforce of tomorrow. 0.5687631070613861\n",
      "In an attempt to build an AI-ready workforce, Microsoft announced Intelligent Cloud Hub which has been launched to empower the next generation of students with AI-ready skills.\n",
      "Envisioned as a three-year collaborative program, Intelligent Cloud Hub will support around 100 institutions with AI infrastructure, course content and curriculum, developer support, development tools and give students access to cloud and AI services.\n",
      "The company will provide AI development tools and Azure AI services such as Microsoft Cognitive Services, Bot Services and Azure Machine Learning.\n",
      "Earlier in April this year, the company announced Microsoft Professional Program In AI as a learning track open to the public.\n"
     ]
    }
   ],
   "source": [
    "clean_sentences = cleanup_sentences(text)\n",
    "words = []\n",
    "for sent in clean_sentences:\n",
    "    words.append(nlkt_word_tokenize(sent))\n",
    "model = Word2Vec(words, min_count=1, sg = 1)\n",
    "summarize(text, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d7359adec4ffe2916680474ceb48a86338759ffb8252cd67d6683f84078a4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
