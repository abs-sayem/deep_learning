{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Sequential Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **When to Use a Sequential Model**\n",
    "\n",
    "A *sequential* model is appropriate for a **plain stack of layers** where each layer has **exactly one input tensor and one output tensor**.\n",
    "\n",
    "The following `sequential` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Sequential model with 3 layers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(2, activation='relu', name='layer1'),\n",
    "    layers.Dense(3, activation='relu', name='layer2'),\n",
    "    layers.Dense(2, name='layer3'),\n",
    "])\n",
    "# Call the model on a test input\n",
    "x = tf.ones((3,3))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is equivalent to this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 layers\n",
    "layer1 = layers.Dense(2, activation='relu', name='layer1')\n",
    "layer2 = layers.Dense(3, activation='relu', name='layer2')\n",
    "layer3 = layers.Dense(2, name='layer3')\n",
    "\n",
    "# Call layers on a test input\n",
    "x = tf.ones((3,3))\n",
    "y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Sequential model is not appropriate when:\n",
    "* model has multiple inputs or multiple outputs\n",
    "* any of the layers has multiple input or multiple outputs\n",
    "* we nedd to do layer sharing\n",
    "* we want non-linear topology(e.g. a residual connection, a multi-branch model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creating a Sequential Model**\n",
    "We can create a Sequential model by passing a list of layers to the Sequential constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(2, activation='relu'),\n",
    "    layers.Dense(3, activation='relu'),\n",
    "    layers.Dense(4),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a Sequential model incrementally via the `add()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='relu'))\n",
    "model.add(layers.Dense(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that- the Sequential constructor accepts a `name` argument, just like any layer or model in Keras. This is useful to annotate TensorBoard grphs with semantically meaningfull names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(name='my_sequential_model')\n",
    "model.add(layers.Dense(2, activation='relu', name='layer1'))\n",
    "model.add(layers.Dense(3, activation='relu', name='layer2'))\n",
    "model.add(layers.Dense(4, name='layer3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Specifying the Input Shape in Advance**\n",
    "Generally, all layers in Keras need to know the shape of their inputs in order to be able to create their weights. So, when we create a layer like this, initially it has no weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = layers.Dense(2)\n",
    "layers.weights  # Empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It creates its weights the first time it is called on an input, since the shape of the weights depends on the shape of the inputs. Naturally, when we instantiate a Sequential model without an input, it isn't built and calling `model.weights` results an error. The weights are created when the model first sees some input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Giving Input Shape:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using `input` Object:** \n",
    "\n",
    "We should start our model by passing an `input` object to the model, so that it knows its input shape from the beginning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(4,)))\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using `input_shape` Argument:** \n",
    "\n",
    "A simple alternative is to just pass an `input_shape` argument to the first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation='relu', input_shape=(4,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Models built with a predefined input shape like this always have weghts(even before seeing any data) and always have a defined output shape. In general, it's recommended best practice to always specify the input shape of a Sequential model in advance if you know what it is.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What to do after we have a model\n",
    "Once our model architecture is ready-\n",
    "* train the model, evaluate it and run inference\n",
    "* save the model to local disk and store it\n",
    "* speed up model training by leveraging multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Common Debugging Workflow (A CNN Persfective)\n",
    "When building a new Sequential architecture, it's useful to incrementally stack layers with `add()` and frequently print model summaries. For instance, this enables us to monitor how a stack of `conv2D` and `MaxPooling2D` layers is downsampling image feature maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 123, 123, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 121, 121, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 40, 40, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 38, 38, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 36, 36, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 10, 10, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Glo  (None, 32)               0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,002\n",
      "Trainable params: 49,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(250, 250, 3)))                     # 250x250 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation='relu'))   # (123, 123, 32)\n",
    "model.add(layers.Conv2D(32, 3, activation='relu'))              # (121, 121, 32)\n",
    "model.add(layers.MaxPooling2D(3))                               # (40, 40, 32)\n",
    "\n",
    "# Can we guess what the current output shape is at this point?\n",
    "# Let's just print it-\n",
    "#model.summary()     # The shape is: (40, 40, 32) downsampled 250 to 40\n",
    "\n",
    "# We can keep downsampling ...\n",
    "model.add(layers.Conv2D(32, 3, activation='relu'))  # (38, 38, 32)\n",
    "model.add(layers.Conv2D(32, 3, activation='relu'))  # (36, 36, 32)\n",
    "model.add(layers.MaxPooling2D(3))                   # (12, 12, 32)\n",
    "model.add(layers.Conv2D(32, 3, activation='relu'))  # (10, 10, 32)\n",
    "model.add(layers.Conv2D(32, 3, activation='relu'))  # (8, 8, 32)\n",
    "model.add(layers.MaxPooling2D(3))                   # (4, 4, 32)\n",
    "\n",
    "# And now let's see the output shape\n",
    "#model.summary()     # Output Shape: (4, 4, 32)\n",
    "\n",
    "# Now we can apply Global MaxPooling\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, add a classification layer\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction with a Sequential Model\n",
    "Once a Sequential model has been build, it behaves liake a **Functial API Model**. This means- evaery layer has an `input` and `output` attribute This attribute can be used- to quickly creating a model that extracts the outputs of all intermediate layers in a Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Sequential Model\n",
    "initial_model = keras.Sequential([\n",
    "    keras.Input(shape=(250, 250, 3)),\n",
    "    layers.Conv2D(32, 5, strides=2, activation='relu'),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "])\n",
    "\n",
    "# Create a Feature Extractor\n",
    "feature_extractor = keras.Model(\n",
    "    inputs = initial_model.input,\n",
    "    outputs = [layer.output for layer in initial_model.layers],\n",
    ")\n",
    "\n",
    "# Call the feature extractor on test input\n",
    "x = tf.ones((1, 250, 250, 3))       # 1=???\n",
    "features = feature_extractor(x)\n",
    "#print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a similar example that only extract features from one layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Sequential Model\n",
    "initial_model = keras.Sequential([\n",
    "    keras.Input(shape=(250, 250, 3)),\n",
    "    layers.Conv2D(32, 5, strides=2, activation='relu'),\n",
    "    layers.Conv2D(32, 3, activation='relu', name='intermediate_layer'),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "])\n",
    "\n",
    "# Create a Feature Extractor\n",
    "feature_extractor = keras.Model(\n",
    "    inputs = initial_model.input,\n",
    "    outputs = initial_model.get_layer(name='intermediate_layer').output,\n",
    ")\n",
    "\n",
    "# Call the feature extractor on test input\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Transfer Learning with a Sequential Model**\n",
    "Transfer learning consists of freezing the bottom layers in a model and only training the top layers. Let's have a look two common transfer learning blueprint involving Sequential models.\n",
    "\n",
    "First, let's assume that we have a Sequential model and we want to freeze all layers except the last one. In this case, we would simply iterate over `model.layers` and set `layer.trainable=False` on each layer, except the last layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(784)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10),\n",
    "])\n",
    "\n",
    "# More likely, we would wnat to first load pre-trained weights\n",
    "#model.load_weights(...)\n",
    "\n",
    "# Freeze all layers except the last one\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile and Train: It will only update the weights of the last layer\n",
    "#model.compile(...)\n",
    "\n",
    "#model.fit(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d7359adec4ffe2916680474ceb48a86338759ffb8252cd67d6683f84078a4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
